{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1",
      "metadata": {},
      "source": [
        "# \ud83d\udd2c Phenotype Classification Project\n",
        "This notebook integrates the entire pipeline using modular code from `src/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add src to path to import modules\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Import our custom modules\n",
        "from utils import load_data, clean_data, encode_labels, split_data, save_model, load_model\n",
        "from train_model import train_random_forest, evaluate_model, plot_confusion_matrix\n",
        "from predict import predict\n",
        "\n",
        "# Standard imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print('\u2705 All modules imported successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3",
      "metadata": {},
      "source": [
        "## \ud83d\udcc2 Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = load_data('../data/dataset.csv')\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "\n",
        "# Clean data\n",
        "df = clean_data(df)\n",
        "\n",
        "# Encode labels\n",
        "df = encode_labels(df, 'label')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_data(df)\n",
        "print(f'Training set: {X_train.shape}')\n",
        "print(f'Test set: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7",
      "metadata": {},
      "source": [
        "## \ud83c\udf32 Train Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model\n",
        "model = train_random_forest(X_train, y_train, n_estimators=200)\n",
        "print('\u2705 Model training complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "preds = evaluate_model(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a11",
      "metadata": {},
      "source": [
        "## \ud83d\udd22 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a12",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_test, preds, save_path='../models/confusion_matrix.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a13",
      "metadata": {},
      "source": [
        "## \ud83d\udcbe Save Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14",
      "metadata": {},
      "outputs": [],
      "source": [
        "save_model(model, '../models/model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15",
      "metadata": {},
      "source": [
        "## \ud83e\udd16 SHAP Explainability Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16",
      "metadata": {},
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Plot SHAP summary\n",
        "if isinstance(shap_values, list):\n",
        "    print(f'Multi-class problem with {len(shap_values)} classes')\n",
        "    shap.summary_plot(shap_values, X_test)\n",
        "else:\n",
        "    print('Binary classification')\n",
        "    shap.summary_plot(shap_values, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a17",
      "metadata": {},
      "source": [
        "## \ud83d\udd2e Make Predictions on New Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Predict on test set\n",
        "predictions, probabilities = predict(model, X_test)\n",
        "\n",
        "print(f'Predictions shape: {predictions.shape}')\n",
        "print(f'First 10 predictions: {predictions[:10]}')\n",
        "print(f'\\nPrediction probabilities shape: {probabilities.shape}')\n",
        "\n",
        "# For new data, uncomment:\n",
        "# new_df = pd.read_csv('../data/new_data.csv')\n",
        "# new_df_clean = clean_data(new_df)\n",
        "# new_predictions, new_probs = predict(model, new_df_clean)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}